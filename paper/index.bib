@article{batchnorm,
  author    = {Sergey Ioffe and
               Christian Szegedy},
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing
               Internal Covariate Shift},
  journal   = {CoRR},
  volume    = {abs/1502.03167},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.03167},
  timestamp = {Mon, 02 Mar 2015 14:17:34 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/IoffeS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{hessianfree,
  title={Learning recurrent neural networks with hessian-free optimization},
  author={Martens, J. and Sutskever, I.},
  booktitle={ICML},
  year={2011}
}

@article{ollivier,
  author    = {Yann Ollivier},
  title     = {Persistent Contextual Neural Networks for learning symbolic data sequences},
  journal   = {CoRR},
  volume    = {abs/1306.0514},
  year      = {2013},
  url       = {http://arxiv.org/abs/1306.0514},
  timestamp = {Mon, 01 Jul 2013 20:31:24 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Ollivier13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{KFAC,
  author    = {James Martens and
               Roger B. Grosse},
  title     = {Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  journal   = {CoRR},
  volume    = {abs/1503.05671},
  year      = {2015},
  url       = {http://arxiv.org/abs/1503.05671},
  timestamp = {Thu, 09 Apr 2015 11:33:20 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MartensG15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{efficientbackprop,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{raiko,
  title={Deep learning made easier by linear transformations in perceptrons},
  author={Raiko, Tapani and Valpola, Harri and LeCun, Yann},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={924--932},
  year={2012}
}

@inproceedings{naturalneuralnetworks,
  title={Natural neural networks},
  author={Desjardins, Guillaume and Simonyan, Karen and Pascanu, Razvan and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2062--2070},
  year={2015}
}

@article{baidu,
  title={Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
  author={Amodei, D. and Anubhai, R. and Battenberg, E. and Case, C. and Casper, J. and Catanzaro, B. and Chen, J. and Chrzanowski, M. and Coates, A. and Diamos, G. and others},
  journal={arXiv:1512.02595},
  year={2015}
}

@article{cesar,
  title={Batch Normalized Recurrent Neural Networks},
  author={Laurent, C. and Pereyra, G. and Brakel, P. and Zhang, Y. and Bengio, Y.},
  journal={ICASSP},
  year={2016}
}

@article{weightnorm,
  title={Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
  author={Salimans, Tim and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1602.07868},
  year={2016}
}

@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, S. and Schmidhuber, J},
  journal={Neural computation},
  year={1997},
  publisher={MIT Press}
}

@article{urnn,
  title={Unitary Evolution Recurrent Neural Networks},
  author={Arjovsky, M. and Shah, A. and Bengio, Y.},
  journal={arXiv:1511.06464},
  year={2015}
}

@article{amari,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@article{pascanudifficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1211.5063},
  year={2012}
}

@article{krueger,
  title={Regularizing RNNs by Stabilizing Activations},
  author={Krueger, D and Memisevic, R.},
  journal={ICLR},
  year={2016}
}

@misc{rmsprop,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

@article{penntreebank,
 author = {M., Mitchell P. and Marcinkiewicz, M. and Santorini, B.},
 title = {Building a Large Annotated Corpus of English: The Penn Treebank},
 journal = {Comput. Linguist.},
 year = {1993},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@article{mahoney2009large,
  title={Large text compression benchmark},
  author={Mahoney, M.},
  year={2009}
}

@inproceedings{attentivereader,
  title={Teaching machines to read and comprehend},
  author={Hermann, K. M. and Kocisky, T. and Grefenstette, E. and Espeholt, L. and Kay, W. and Suleyman, M. and Blunsom, P.},
  booktitle={NIPS},
  year={2015}
}

@MISC{theano2,
        author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian J. and Bergeron, Arnaud and Bouchard, Nicolas and Bengio, Yoshua},
         title = {Theano: new features and speed improvements},
          year = {2012},
  howpublished = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
      abstract = {Theano is a linear algebra compiler that optimizes a user’s symbolically-speciﬁed
mathematical computations to produce efﬁcient low-level implementations. In
this paper, we present new features and efﬁciency improvements to Theano, and
benchmarks demonstrating Theano’s performance relative to Torch7, a recently
introduced machine learning library, and to RNNLM, a C++ library targeted at
recurrent neural networks.}
}

@INPROCEEDINGS{theano1,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@article{blocks,
  author    = {Bart van Merri{\"{e}}nboer and
               Dzmitry Bahdanau and
               Vincent Dumoulin and
               Dmitriy Serdyuk and
               David Warde{-}Farley and
               Jan Chorowski and
               Yoshua Bengio},
  title     = {Blocks and Fuel: Frameworks for deep learning},
  journal   = {CoRR},
  volume    = {abs/1506.00619},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.00619},
  timestamp = {Wed, 01 Jul 2015 15:10:24 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MerrienboerBDSW15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{le2015simple,
  title={A Simple Way to Initialize Recurrent Networks of Rectified Linear Units},
  author={Le, Quoc V and Jaitly, N. and Hinton, G.},
  journal={arXiv:1504.00941},
  year={2015}
}

@article{zhang2016architectural,
  title={Architectural Complexity Measures of Recurrent Neural Networks},
  author={Zhang, S. and Wu, Y. and Che, T. and Lin, Z. and Memisevic, R. and Salakhutdinov, R. and Bengio, Y.},
  journal={arXiv:1602.08210},
  year={2016}
}


@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, D. and Cho, K. and Bengio, Y.},
  journal={ICLR},
  year={2015}
}


@article{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, K. and Ba, J. and Kiros, R. and Courville, A. and Salakhutdinov, R. and Zemel, R. and Bengio, Y.},
  journal={arXiv:1502.03044},
  year={2015}
}

@inproceedings{yao2015describing,
  title={Describing videos by exploiting temporal structure},
  author={Yao, L. and Torabi, A. and Cho, K. and Ballas, N. and Pal, C. and Larochelle, H. and Courville, A.},
  booktitle={ICCV},
  year={2015}
}

@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Y. and Simard, P. and Frasconi, P.},
  journal={Neural Networks, IEEE Transactions on},
  year={1994},
  publisher={IEEE}
}


@article{hochreiter1991untersuchungen,
  title={Untersuchungen zu dynamischen neuronalen Netzen},
  author={Hochreiter, S.},
  journal={Master's thesis},
  year={1991}
}

@article{cho2014learning,
  title={Learning phrase representations using rnn encoder-decoder for statistical machine translation},
  author={Cho, K. and Van Merri{\"e}nboer, B. and Gulcehre, C. and Bahdanau, D. and Bougares, F. and Schwenk, H. and Bengio, Y.},
  journal={arXiv:1406.1078},
  year={2014}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Cognitive modeling},
 year={1988}
}

@article{shimodaira2000improving,
  title={Improving predictive inference under covariate shift by weighting the log-likelihood function},
  author={Shimodaira, H.},
  journal={Journal of statistical planning and inference},
  year={2000},
  publisher={Elsevier}
}

@article{mikolov2012subword,
  title={Subword language modeling with neural networks},
  author={Mikolov, T. and Sutskever, I. and Deoras, A. and Le, H. and Kombrink, S. and Cernocky, J.},
  journal={preprint},
  year={2012}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, A.},
  journal={arXiv:1308.0850},
  year={2013}
}

@article{pachitariu2013regularization,
  title={Regularization and nonlinearities for neural language models: when are they needed?},
  author={Pachitariu, Marius and Sahani, Maneesh},
  journal={arXiv preprint arXiv:1301.5650},
  year={2013}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, D. and Ba, J.},
  journal={arXiv:1412.6980},
  year={2014}
}
